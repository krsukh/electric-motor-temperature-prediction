# -*- coding: utf-8 -*-
"""randomforestprojectfinalbigdatarandomizedsearchhyperparameter.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/18eU44uOEGUZVbzeW6jYyLexIwQVPztJl
"""

import pandas as pd
import numpy as np
import seaborn as sns

# this file is about randomized search cv that helps for hyperparameter tuning in random forest regression method

data_raw = pd.read_csv("measures_v2.csv")
data_copy = data_raw.copy(deep=True)

print(data_raw.shape)

from sklearn.ensemble import RandomForestRegressor
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import GridSearchCV


from sklearn.model_selection import cross_val_score, train_test_split
from sklearn.feature_selection import mutual_info_regression
from sklearn.feature_selection import VarianceThreshold
from sklearn.feature_selection import SelectKBest, SelectPercentile
from sklearn.metrics import accuracy_score
from sklearn.metrics import r2_score
from sklearn.metrics import mean_squared_error
from sklearn.metrics import mean_absolute_error
from sklearn.preprocessing import MinMaxScaler

data_raw['profile_id'].value_counts()

#target_variables = ['pm', 'stator_yoke', 'stator_winding', 'stator_tooth']

target_variables = ['stator_winding']
drop_cols = ['profile_id']

profile_list = np.array([i for i in data_raw['profile_id'].unique() if i < 81])

profile_list

cols = [item for item in list(data_copy.columns) if item not in drop_cols + target_variables]

cols

scaler = MinMaxScaler()
data_copy[cols] = scaler.fit_transform(data_copy[cols])

data_copy[cols]

# divide data in train data and test data.
data_train = data_copy[data_copy['profile_id'].isin(profile_list)]
data_test = data_copy[data_copy['profile_id'] == 81]

data_train

data_test



#import seaborn as sns
#import matplotlib.pyplot as plt
#plt.figure(figsize=(12,10))
#corrmat = data_train.corr()
#sns.heatmap(corrmat, annot=True, cmap=plt.cm.CMRmap_r)
#plt.show()

#select highly correlated features so there is a function correlation for this
#def correlation(dataset, thresold):
#  col_corr = set()
#  corr_matrix = dataset.corr()
 # for i in range(len(corr_matrix.columns)):
  #  for j in range(i):
   #   if abs(corr_matrix.iloc[i, j]) > thresold:
    #    colname = corr_matrix.columns[i]
     #   col_corr.add(colname)
  #return col_corr

#corr_features = correlation(data_train, 0.7)
#len(set(corr_features))

#corr_features

#data_train = data_train.drop(corr_features,axis=1)
#data_test = data_test.drop(corr_features,axis=1)

x_train = data_train.drop(columns = target_variables + drop_cols)
y_train = data_train[target_variables]

x_train

y_train

x_train.head()

from sklearn.model_selection import RandomizedSearchCV

n_estimators = [int(x) for x in np.linspace(start = 10, stop = 500, num = 10)]
#n_estimators : (10,30,50,70,90,100)
max_features = ['auto','sqrt','log2']
max_depth = [2,4,6,8,10,12]
min_samples_split = [2,5]
min_samples_leaf = [1,2]
bootstrap = [True, False]

param_grid = {'n_estimators' : n_estimators,
              'max_features' : max_features,
              'max_depth' : max_depth,
              'min_samples_split' : min_samples_split,
              'min_samples_leaf' : min_samples_leaf,
              'bootstrap' : bootstrap}
print(param_grid)

rf_model = RandomForestRegressor()
#rf = RandomForestRegressor()
#rf = RandomForestRegressor(bootstrap=False, max_depth=None, max_features='sqrt', max_leaf_nodes=None, min_impurity_decrease= 0.0, min_samples_leaf=1, min_samples_split=6, min_weight_fraction_leaf=0.0, n_estimators=150, n_jobs=-1, oob_score=False, random_state=None, verbose=0, warm_start=False)

RF_grid = RandomizedSearchCV(estimator = rf_model, param_distributions=param_grid, cv = 2, verbose=1, n_jobs=4)

#y = y_train.ravel()
#y_train = np.array(y).astype(int)

#RF_grid.fit(x_train, y_train)
RF_grid.fit(x_train, y_train.values.ravel())

x_test = data_test.drop(columns = target_variables + drop_cols)
y_test_actual = data_test[target_variables]

RF_grid.best_estimator_

RF_grid.best_score_

y_test_prediction = RF_grid.predict(x_test)
#print(f'r2score - : {rf.score(x_test,y_test_actual):.6f}')
#print(f'Test Accuracy - : {RF_grid_model.score(x_test,y_test):.3f}')

r2_score(y_test_actual, y_test_prediction)

mean_squared_error(y_test_actual, y_test_prediction)

mean_absolute_error(y_test_actual, y_test_prediction)